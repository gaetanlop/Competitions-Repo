{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-01-01T09:29:53.537090Z",
     "iopub.status.busy": "2021-01-01T09:29:53.536405Z",
     "iopub.status.idle": "2021-01-01T09:29:54.893521Z",
     "shell.execute_reply": "2021-01-01T09:29:54.892293Z"
    },
    "papermill": {
     "duration": 1.382209,
     "end_time": "2021-01-01T09:29:54.893735",
     "exception": false,
     "start_time": "2021-01-01T09:29:53.511526",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type='text/css'>\n",
       ".datatable table.frame { margin-bottom: 0; }\n",
       ".datatable table.frame thead { border-bottom: none; }\n",
       ".datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n",
       ".datatable .bool    { background: #DDDD99; }\n",
       ".datatable .object  { background: #565656; }\n",
       ".datatable .int     { background: #5D9E5D; }\n",
       ".datatable .float   { background: #4040CC; }\n",
       ".datatable .str     { background: #CC4040; }\n",
       ".datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n",
       ".datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n",
       ".datatable th:nth-child(2) { padding-left: 12px; }\n",
       ".datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n",
       ".datatable .footer { font-size: 9px; }\n",
       ".datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gc\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from collections import defaultdict\n",
    "from tqdm.notebook import tqdm\n",
    "import lightgbm as lgb\n",
    "import riiideducation\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "from scipy import stats\n",
    "\n",
    "import random\n",
    "import os\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "execution": {
     "iopub.execute_input": "2021-01-01T09:29:54.938114Z",
     "iopub.status.busy": "2021-01-01T09:29:54.937310Z",
     "iopub.status.idle": "2021-01-01T09:29:54.940974Z",
     "shell.execute_reply": "2021-01-01T09:29:54.940437Z"
    },
    "papermill": {
     "duration": 0.024659,
     "end_time": "2021-01-01T09:29:54.941114",
     "exception": false,
     "start_time": "2021-01-01T09:29:54.916455",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Random seed\n",
    "SEED = 123\n",
    "\n",
    "# Function to seed everything\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    \n",
    "seed_everything(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.014296,
     "end_time": "2021-01-01T09:29:54.970139",
     "exception": false,
     "start_time": "2021-01-01T09:29:54.955843",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Prior Question Elapsed time mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-01T09:29:55.003005Z",
     "iopub.status.busy": "2021-01-01T09:29:55.002213Z",
     "iopub.status.idle": "2021-01-01T09:29:55.007224Z",
     "shell.execute_reply": "2021-01-01T09:29:55.007906Z"
    },
    "papermill": {
     "duration": 0.023368,
     "end_time": "2021-01-01T09:29:55.008056",
     "exception": false,
     "start_time": "2021-01-01T09:29:54.984688",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "prior_question_elapsed_time_mean=15162.5927734375"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.014177,
     "end_time": "2021-01-01T09:29:55.037691",
     "exception": false,
     "start_time": "2021-01-01T09:29:55.023514",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Features Dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-01T09:29:55.070690Z",
     "iopub.status.busy": "2021-01-01T09:29:55.069974Z",
     "iopub.status.idle": "2021-01-01T09:29:55.097119Z",
     "shell.execute_reply": "2021-01-01T09:29:55.097728Z"
    },
    "papermill": {
     "duration": 0.045836,
     "end_time": "2021-01-01T09:29:55.097961",
     "exception": false,
     "start_time": "2021-01-01T09:29:55.052125",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Funcion for user stats with loops\n",
    "def add_features(df, answered_correctly_u_count, answered_correctly_u_sum, elapsed_time_u_sum, explanation_u_sum, timestamp_u, timestamp_u_incorrect, answered_correctly_uq,timestamp_l, nb_l_watched, part_u_count,part_u_sum, tags_u_count,tags_u_sum,first_bundle_dict,community_u_sum,community_u_count,timestamp_u_correct): \n",
    "    \n",
    "    # -----------------------------------------------------------------------\n",
    "    for num, row in enumerate(df[['user_id', 'answered_correctly', 'content_id', 'prior_question_elapsed_time', 'prior_question_had_explanation', 'timestamp','content_type_id','part','tags1','bundle_id','community']].values): \n",
    "        \n",
    "        if row[6]==False:\n",
    "            \n",
    "            # Client features updates\n",
    "            answered_correctly_u_count[row[0]] += 1\n",
    "            answered_correctly_u_sum[row[0]] += row[1]\n",
    "            part_u_count[row[0]][row[7]]+=1\n",
    "            part_u_sum[row[0]][row[7]]+= row[1]\n",
    "            tags_u_sum[row[0]][row[8]]+= row[1]\n",
    "            tags_u_count[row[0]][row[8]]+=1\n",
    "            elapsed_time_u_sum[row[0]] += row[3]\n",
    "            explanation_u_sum[row[0]] += int(row[4])\n",
    "            \n",
    "            if row[1]==1:\n",
    "                timestamp_u_correct[row[0]]=row[5]\n",
    "            \n",
    "            if len(timestamp_u[row[0]]) == 3:\n",
    "                timestamp_u[row[0]].pop(0)\n",
    "                timestamp_u[row[0]].append(row[5])\n",
    "            else:\n",
    "                timestamp_u[row[0]].append(row[5])\n",
    "            \n",
    "            if row[1] == 0:\n",
    "                if len(timestamp_u_incorrect[row[0]]) == 1:\n",
    "                    timestamp_u_incorrect[row[0]].pop(0)\n",
    "                    timestamp_u_incorrect[row[0]].append(row[5])\n",
    "                else:\n",
    "                    timestamp_u_incorrect[row[0]].append(row[5])\n",
    "            \n",
    "            # ------------------------------------------------------------------\n",
    "            # Community features updates\n",
    "            community_u_count[row[0]][row[10]]+=1\n",
    "            community_u_sum[row[0]][row[10]]+= row[1]\n",
    "            # ------------------------------------------------------------------\n",
    "            # Bundle features updates\n",
    "            if first_bundle_dict[row[0]]==0:\n",
    "                first_bundle_dict[row[0]]=row[9]\n",
    "            # ------------------------------------------------------------------\n",
    "            # Client Question updates\n",
    "            answered_correctly_uq[row[0]][row[2]] += 1\n",
    "           \n",
    "            \n",
    "        else:\n",
    "            \n",
    "\n",
    "            nb_l_watched[row[0]]+=1\n",
    "            \n",
    "            timestamp_l[row[0]]=row[5]\n",
    "            \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-01T09:29:55.136596Z",
     "iopub.status.busy": "2021-01-01T09:29:55.135811Z",
     "iopub.status.idle": "2021-01-01T09:29:55.177362Z",
     "shell.execute_reply": "2021-01-01T09:29:55.178292Z"
    },
    "papermill": {
     "duration": 0.063727,
     "end_time": "2021-01-01T09:29:55.178514",
     "exception": false,
     "start_time": "2021-01-01T09:29:55.114787",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def read_and_preprocess(feature_engineering = False):\n",
    "    \n",
    "    # Client dictionaries\n",
    "    answered_correctly_u_count = defaultdict(int)\n",
    "    answered_correctly_u_sum = defaultdict(int)\n",
    "    elapsed_time_u_sum = defaultdict(int)\n",
    "    explanation_u_sum = defaultdict(int)\n",
    "    timestamp_u = defaultdict(list)\n",
    "    timestamp_u_incorrect = defaultdict(list)\n",
    "    timestamp_u_correct = defaultdict(int)\n",
    "    part_u_count=defaultdict(lambda: defaultdict(int))\n",
    "    part_u_sum=defaultdict(lambda: defaultdict(int))\n",
    "    tags_u_count=defaultdict(lambda: defaultdict(int))\n",
    "    tags_u_sum=defaultdict(lambda: defaultdict(int))\n",
    "    \n",
    "    # Community dictionaries\n",
    "    community_u_count=defaultdict(lambda: defaultdict(int))\n",
    "    community_u_sum=defaultdict(lambda: defaultdict(int))\n",
    "    \n",
    "    # Bundle dictionaries\n",
    "    first_bundle_dict=defaultdict(int)\n",
    "    \n",
    "    # Client Question dictionary\n",
    "    answered_correctly_uq = defaultdict(lambda: defaultdict(int))\n",
    "    \n",
    "    # Lectures dictionaries\n",
    "    timestamp_l=defaultdict(int)\n",
    "    nb_l_watched=defaultdict(int)\n",
    "    \n",
    "    # --------------------------------------------------------------------\n",
    "    # --------------------------------------------------------------------\n",
    "    \n",
    "    train_pickle = '../input/riiid-cross-validation-files/cv1_train.pickle'\n",
    "    valid_pickle = '../input/riiid-cross-validation-files/cv1_valid.pickle'\n",
    "    question_file = '../input/import-for-gcp/communities.csv'\n",
    "    \n",
    "    # Merge with question dataframe\n",
    "    questions_df = pd.read_csv(question_file)[['question_id','part','community','bundle_id','tags1']]\n",
    "    questions_df['part'] = questions_df['part'].astype(np.int8)\n",
    "    questions_df['community'] = questions_df['community'].astype(np.int8)\n",
    "    questions_df['bundle_id'] = questions_df['bundle_id'].astype(np.int32)\n",
    "    questions_df['tags1']=questions_df['tags1'].astype(np.int16)\n",
    "    #questions_df['tags_encoded']=questions_df['tags_encoded'].astype(np.int16)\n",
    "    \n",
    "    \n",
    "    gc.collect()\n",
    "    \n",
    "    # Read data\n",
    "    feld_needed = ['timestamp', 'user_id', 'answered_correctly', 'content_id', 'content_type_id', 'prior_question_elapsed_time', 'prior_question_had_explanation']\n",
    "    train = pd.read_pickle(train_pickle)[feld_needed].iloc[-50000000:]\n",
    "    \n",
    "    # Changing dtype to avoid lightgbm error\n",
    "    train['prior_question_had_explanation'] = train.prior_question_had_explanation.fillna(False).astype('int8')\n",
    "    \n",
    "    \n",
    "    # Fill prior question elapsed time with the mean\n",
    "    train['prior_question_elapsed_time'].fillna(prior_question_elapsed_time_mean, inplace = True)\n",
    "    \n",
    "    \n",
    "    \n",
    "    train = pd.merge(train, questions_df[['question_id', 'part','tags1','bundle_id','community']], left_on = 'content_id', right_on = 'question_id', how = 'left')\n",
    "    \n",
    "    \n",
    "    print('User feature calculation started...')\n",
    "    print('\\n')\n",
    "    train = add_features(train, answered_correctly_u_count, answered_correctly_u_sum, elapsed_time_u_sum, explanation_u_sum, timestamp_u, timestamp_u_incorrect, answered_correctly_uq, timestamp_l,nb_l_watched, part_u_count,part_u_sum, tags_u_count,tags_u_sum, first_bundle_dict, community_u_sum,community_u_count, timestamp_u_correct)\n",
    "    \n",
    "    del train\n",
    "    gc.collect()\n",
    "    \n",
    "    print('Second Iteration')\n",
    "    \n",
    "    train = pd.read_pickle(train_pickle)[feld_needed].iloc[-90000000:-50000000]\n",
    "    \n",
    "    # Changing dtype to avoid lightgbm error\n",
    "    train['prior_question_had_explanation'] = train.prior_question_had_explanation.fillna(False).astype('int8')\n",
    "    \n",
    "    # Fill prior question elapsed time with the mean\n",
    "    train['prior_question_elapsed_time'].fillna(prior_question_elapsed_time_mean, inplace = True)\n",
    "    \n",
    "    # Merge\n",
    "    train = pd.merge(train, questions_df[['question_id', 'part','tags1','bundle_id','community']], left_on = 'content_id', right_on = 'question_id', how = 'left')\n",
    "    gc.collect()\n",
    "    \n",
    "    print('User feature calculation started...')\n",
    "    print('\\n')\n",
    "    train = add_features(train, answered_correctly_u_count, answered_correctly_u_sum, elapsed_time_u_sum, explanation_u_sum, timestamp_u, timestamp_u_incorrect, answered_correctly_uq, timestamp_l,nb_l_watched, part_u_count,part_u_sum, tags_u_count,tags_u_sum, first_bundle_dict, community_u_sum,community_u_count, timestamp_u_correct)\n",
    "    \n",
    "    del train\n",
    "    gc.collect()\n",
    "    \n",
    "    \n",
    "    \n",
    "    print('valid')\n",
    "    \n",
    "\n",
    "    \n",
    "    valid = pd.read_pickle(valid_pickle)[feld_needed]\n",
    "    \n",
    "    # Changing dtype to avoid lightgbm error\n",
    "    valid['prior_question_had_explanation'] = valid.prior_question_had_explanation.fillna(False).astype('int8')\n",
    "    \n",
    "    # Fill prior question elapsed time with the mean\n",
    "    valid['prior_question_elapsed_time'].fillna(prior_question_elapsed_time_mean, inplace = True)\n",
    "    \n",
    "    # Merge\n",
    "    valid = pd.merge(valid, questions_df[['question_id', 'part','tags1','bundle_id','community']], left_on = 'content_id', right_on = 'question_id', how = 'left')\n",
    "        \n",
    "    print('User feature calculation started...')\n",
    "    print('\\n')\n",
    "    valid = add_features(valid, answered_correctly_u_count, answered_correctly_u_sum, elapsed_time_u_sum, explanation_u_sum, timestamp_u, timestamp_u_incorrect, answered_correctly_uq, timestamp_l,nb_l_watched, part_u_count,part_u_sum, tags_u_count,tags_u_sum, first_bundle_dict, community_u_sum,community_u_count, timestamp_u_correct)\n",
    "    \n",
    "    del valid\n",
    "    gc.collect()\n",
    "    \n",
    "    print('Creating Features Dicts')\n",
    "    \n",
    "    features_dicts = {\n",
    "        'answered_correctly_u_count': answered_correctly_u_count,\n",
    "        'answered_correctly_u_sum': answered_correctly_u_sum,\n",
    "        'elapsed_time_u_sum': elapsed_time_u_sum,\n",
    "        'explanation_u_sum': explanation_u_sum,\n",
    "        'answered_correctly_uq': answered_correctly_uq,\n",
    "        'timestamp_u': timestamp_u,\n",
    "        'timestamp_u_incorrect': timestamp_u_incorrect,\n",
    "        'timestamp_u_correct':timestamp_u_correct,\n",
    "        'nb_l_watched':nb_l_watched,\n",
    "        'timestamp_l':timestamp_l,\n",
    "        'part_u_count':part_u_count,\n",
    "        'part_u_sum':part_u_sum,\n",
    "        'tags_u_count':tags_u_count,\n",
    "        'tags_u_sum':tags_u_sum,\n",
    "        'first_bundle_dict': first_bundle_dict,\n",
    "        'community_u_count': community_u_count,\n",
    "        'community_u_sum':community_u_sum\n",
    "        \n",
    "    }\n",
    "\n",
    "    \n",
    "    return features_dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-01T09:29:55.212353Z",
     "iopub.status.busy": "2021-01-01T09:29:55.211578Z",
     "iopub.status.idle": "2021-01-01T10:18:37.952705Z",
     "shell.execute_reply": "2021-01-01T10:18:37.953473Z"
    },
    "papermill": {
     "duration": 2922.760054,
     "end_time": "2021-01-01T10:18:37.953952",
     "exception": false,
     "start_time": "2021-01-01T09:29:55.193898",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User feature calculation started...\n",
      "\n",
      "\n",
      "Second Iteration\n",
      "User feature calculation started...\n",
      "\n",
      "\n",
      "valid\n",
      "User feature calculation started...\n",
      "\n",
      "\n",
      "Creating Features Dicts\n",
      "CPU times: user 46min 27s, sys: 48.1 s, total: 47min 15s\n",
      "Wall time: 48min 42s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "features_dicts = read_and_preprocess(feature_engineering = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.019311,
     "end_time": "2021-01-01T10:18:37.992271",
     "exception": false,
     "start_time": "2021-01-01T10:18:37.972960",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# AGG FILE AND PART FILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-01T10:18:51.957160Z",
     "iopub.status.busy": "2021-01-01T10:18:51.956354Z",
     "iopub.status.idle": "2021-01-01T10:18:51.960392Z",
     "shell.execute_reply": "2021-01-01T10:18:51.959784Z"
    },
    "papermill": {
     "duration": 13.95058,
     "end_time": "2021-01-01T10:18:51.960510",
     "exception": false,
     "start_time": "2021-01-01T10:18:38.009930",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-01T10:18:52.020631Z",
     "iopub.status.busy": "2021-01-01T10:18:52.019924Z",
     "iopub.status.idle": "2021-01-01T10:18:52.057689Z",
     "shell.execute_reply": "2021-01-01T10:18:52.057090Z"
    },
    "papermill": {
     "duration": 0.07917,
     "end_time": "2021-01-01T10:18:52.057823",
     "exception": false,
     "start_time": "2021-01-01T10:18:51.978653",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "questions_df = pd.read_csv('../input/import-for-gcp/communities.csv')\n",
    "questions_df['part'] = questions_df['part'].astype(np.int8)\n",
    "questions_df['community'] = questions_df['community'].astype(np.int8)\n",
    "questions_df['bundle_id'] = questions_df['bundle_id'].astype(np.int32)\n",
    "questions_df['tags1']=questions_df['tags1'].astype(np.int16)\n",
    "questions_df['tags_encoded']=questions_df['tags_encoded'].astype(np.int16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-01T10:18:52.103404Z",
     "iopub.status.busy": "2021-01-01T10:18:52.102575Z",
     "iopub.status.idle": "2021-01-01T10:18:52.150938Z",
     "shell.execute_reply": "2021-01-01T10:18:52.151536Z"
    },
    "papermill": {
     "duration": 0.07604,
     "end_time": "2021-01-01T10:18:52.151720",
     "exception": false,
     "start_time": "2021-01-01T10:18:52.075680",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "agg_file='../input/import-for-gcp/features.pkl'\n",
    "part_file='../input/import-for-gcp/part.pkl'\n",
    "\n",
    "agg=pd.read_pickle(agg_file)\n",
    "agg['question_correctly_q_count']=agg['question_correctly_q_count'].astype(np.int32)\n",
    "agg['question_correctly_q_mean']=agg['question_correctly_q_mean'].astype(np.float32)\n",
    "agg['question_elapsed_time_mean']=agg['question_elapsed_time_mean'].astype(np.float32)\n",
    "agg['question_had_explanation_mean']=agg['question_had_explanation_mean'].astype(np.float32)\n",
    "\n",
    "part=pd.read_pickle(part_file)\n",
    "part['part_elapsed_time_mean']=part['part_elapsed_time_mean'].astype(np.int32)\n",
    "part['part_had_explanation_mean']=part['part_had_explanation_mean'].astype(np.float32)\n",
    "part['part_correctly_q_mean']=part['part_correctly_q_mean'].astype(np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.017372,
     "end_time": "2021-01-01T10:18:52.186913",
     "exception": false,
     "start_time": "2021-01-01T10:18:52.169541",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Target / Features / Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-01T10:18:52.226878Z",
     "iopub.status.busy": "2021-01-01T10:18:52.225833Z",
     "iopub.status.idle": "2021-01-01T10:18:56.253021Z",
     "shell.execute_reply": "2021-01-01T10:18:56.252270Z"
    },
    "papermill": {
     "duration": 4.048376,
     "end_time": "2021-01-01T10:18:56.253141",
     "exception": false,
     "start_time": "2021-01-01T10:18:52.204765",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "TARGET = 'answered_correctly'\n",
    "    \n",
    "# Features to train and predict\n",
    "FEATURES = ['prior_question_elapsed_time', 'part', 'prior_question_had_explanation',  \n",
    "                'answered_correctly_u_avg', 'elapsed_time_u_avg', 'explanation_u_avg', 'question_correctly_q_count',\n",
    "                'question_correctly_q_mean', 'question_had_explanation_mean','question_elapsed_time_mean',\n",
    "                'answered_correctly_uq_count','timestamp_u_correct_recency',\n",
    "                'timestamp_u_recency_1', 'timestamp_u_recency_2', 'timestamp_u_recency_3', \n",
    "                'timestamp_u_incorrect_recency','tags1', 'part_elapsed_time_mean','part_had_explanation_mean',\n",
    "                'part_correctly_q_mean',\n",
    "                'nb_u_lect_watched','timestamp_l_recency_1','part_u_avg','tags_u_avg','user_count','user_part_count',\n",
    "               'first_bundle','community',\n",
    "                'community_u_avg','tags_encoded']\n",
    "\n",
    "model = pickle.load(open('../input/best-ever-done/lgbm_80M_30.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.017762,
     "end_time": "2021-01-01T10:18:56.289275",
     "exception": false,
     "start_time": "2021-01-01T10:18:56.271513",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-01T10:18:56.339862Z",
     "iopub.status.busy": "2021-01-01T10:18:56.334790Z",
     "iopub.status.idle": "2021-01-01T10:18:56.351000Z",
     "shell.execute_reply": "2021-01-01T10:18:56.350407Z"
    },
    "papermill": {
     "duration": 0.043785,
     "end_time": "2021-01-01T10:18:56.351129",
     "exception": false,
     "start_time": "2021-01-01T10:18:56.307344",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def update_features(df, answered_correctly_u_count, answered_correctly_u_sum, elapsed_time_u_sum, explanation_u_sum, timestamp_u, timestamp_u_incorrect, answered_correctly_uq,timestamp_l, nb_l_watched, part_u_count,part_u_sum, tags_u_count,tags_u_sum,first_bundle_dict,community_u_sum,community_u_count, timestamp_u_correct):\n",
    "    \n",
    "    for row in df[['user_id', 'answered_correctly', 'content_id', 'prior_question_elapsed_time', 'prior_question_had_explanation', 'timestamp','content_type_id','part','tags1','bundle_id','community']].values:\n",
    "        \n",
    "        if row[6]==0:\n",
    "            # ------------------------------------------------------------------\n",
    "            # Client features updates\n",
    "            answered_correctly_u_count[row[0]] += 1\n",
    "            answered_correctly_u_sum[row[0]] += row[1]\n",
    "            part_u_count[row[0]][row[7]]+=1\n",
    "            part_u_sum[row[0]][row[7]]+= row[1]\n",
    "            tags_u_sum[row[0]][row[8]]+= row[1]\n",
    "            tags_u_count[row[0]][row[8]]+=1\n",
    "            elapsed_time_u_sum[row[0]] += row[3]\n",
    "            explanation_u_sum[row[0]] += int(row[4])\n",
    "            \n",
    "            if row[1]==1:\n",
    "                timestamp_u_correct[row[0]]=row[5]\n",
    "            \n",
    "            if len(timestamp_u[row[0]]) == 3:\n",
    "                timestamp_u[row[0]].pop(0)\n",
    "                timestamp_u[row[0]].append(row[5])\n",
    "            else:\n",
    "                timestamp_u[row[0]].append(row[5])\n",
    "            \n",
    "            if row[1] == 0:\n",
    "                if len(timestamp_u_incorrect[row[0]]) == 1:\n",
    "                    timestamp_u_incorrect[row[0]].pop(0)\n",
    "                    timestamp_u_incorrect[row[0]].append(row[5])\n",
    "                else:\n",
    "                    timestamp_u_incorrect[row[0]].append(row[5])\n",
    "            \n",
    "            # ------------------------------------------------------------------\n",
    "            # Community features updates\n",
    "            community_u_count[row[0]][row[10]]+=1\n",
    "            community_u_sum[row[0]][row[10]]+= row[1]\n",
    "            # ------------------------------------------------------------------\n",
    "            # Bundle features updates\n",
    "            if first_bundle_dict[row[0]]==0:\n",
    "                first_bundle_dict[row[0]]=row[9]\n",
    "            # ------------------------------------------------------------------\n",
    "            # Client Question updates\n",
    "            answered_correctly_uq[row[0]][row[2]] += 1\n",
    "\n",
    "            \n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-01T10:18:56.419357Z",
     "iopub.status.busy": "2021-01-01T10:18:56.396729Z",
     "iopub.status.idle": "2021-01-01T10:18:56.448273Z",
     "shell.execute_reply": "2021-01-01T10:18:56.447693Z"
    },
    "papermill": {
     "duration": 0.078939,
     "end_time": "2021-01-01T10:18:56.448403",
     "exception": false,
     "start_time": "2021-01-01T10:18:56.369464",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def add_features_inf(df, answered_correctly_u_count, answered_correctly_u_sum, elapsed_time_u_sum, explanation_u_sum, timestamp_u, timestamp_u_incorrect, answered_correctly_uq,timestamp_l, nb_l_watched, part_u_count,part_u_sum, tags_u_count,tags_u_sum,first_bundle_dict,community_u_sum,community_u_count,timestamp_u_correct):\n",
    "    iteration=0\n",
    "    # -----------------------------------------------------------------------\n",
    "    # Client features\n",
    "    answered_correctly_u_avg = np.zeros(len(df[df.content_type_id==False]), dtype = np.float32)\n",
    "    elapsed_time_u_avg = np.zeros(len(df[df.content_type_id==False]), dtype = np.float32)\n",
    "    explanation_u_avg = np.zeros(len(df[df.content_type_id==False]), dtype = np.float32)\n",
    "    timestamp_u_recency_1 = np.zeros(len(df[df.content_type_id==False]), dtype = np.float32)\n",
    "    timestamp_u_recency_2 = np.zeros(len(df[df.content_type_id==False]), dtype = np.float32)\n",
    "    timestamp_u_recency_3 = np.zeros(len(df[df.content_type_id==False]), dtype = np.float32)\n",
    "    timestamp_u_incorrect_recency = np.zeros(len(df[df.content_type_id==False]), dtype = np.float32)\n",
    "    timestamp_u_correct_recency = np.zeros(len(df[df.content_type_id==False]), dtype = np.float32)\n",
    "    part_u_avg=np.zeros(len(df[df.content_type_id==False]), dtype = np.float32)\n",
    "    tags_u_avg=np.zeros(len(df[df.content_type_id==False]),dtype=np.float32)\n",
    "    user_count=np.zeros(len(df[df.content_type_id==False]),dtype=np.int32)\n",
    "    user_part_count=np.zeros(len(df[df.content_type_id==False]),dtype=np.int32)\n",
    "    # -----------------------------------------------------------------------\n",
    "    # Bundle features\n",
    "    first_bundle= np.zeros(len(df[df.content_type_id==False]),dtype=np.float32)\n",
    "    # -----------------------------------------------------------------------\n",
    "    #Community features\n",
    "    community_u_avg = np.zeros(len(df[df.content_type_id==False]), dtype = np.float32)\n",
    "    # -----------------------------------------------------------------------\n",
    "    # User Question\n",
    "    answered_correctly_uq_count = np.zeros(len(df[df.content_type_id==False]), dtype = np.int32)\n",
    "    # -----------------------------------------------------------------------\n",
    "    # Lecture feature\n",
    "    timestamp_l_recency_1 = np.zeros(len(df[df.content_type_id==False]), dtype = np.float32)\n",
    "    #timestamp_l_recency_2 = np.zeros(len(df[df.content_type_id==False]), dtype = np.float32)\n",
    "    nb_u_lect_watched= np.zeros(len(df[df.content_type_id==False]), dtype = np.int16)\n",
    "    \n",
    "    # -----------------------------------------------------------------------\n",
    "    for num, row in enumerate(df[['user_id', 'content_id', 'prior_question_elapsed_time', 'prior_question_had_explanation', 'timestamp','content_type_id','part','tags1','bundle_id','community']].values):\n",
    "        \n",
    "        num=num-iteration\n",
    "        if row[5]==0:\n",
    "            # Client features assignation\n",
    "            # ------------------------------------------------------------------\n",
    "            if answered_correctly_u_count[row[0]] != 0:\n",
    "                answered_correctly_u_avg[num] = answered_correctly_u_sum[row[0]] / answered_correctly_u_count[row[0]]\n",
    "                elapsed_time_u_avg[num] = elapsed_time_u_sum[row[0]] / answered_correctly_u_count[row[0]]\n",
    "                explanation_u_avg[num] = explanation_u_sum[row[0]] / answered_correctly_u_count[row[0]]\n",
    "            else:\n",
    "                answered_correctly_u_avg[num] = np.nan\n",
    "                elapsed_time_u_avg[num] = np.nan\n",
    "                explanation_u_avg[num] = np.nan\n",
    "\n",
    "            if len(timestamp_u[row[0]]) == 0:\n",
    "                timestamp_u_recency_1[num] = np.nan\n",
    "                timestamp_u_recency_2[num] = np.nan\n",
    "                timestamp_u_recency_3[num] = np.nan\n",
    "                \n",
    "            elif len(timestamp_u[row[0]]) == 1:\n",
    "                timestamp_u_recency_1[num] = row[4] - timestamp_u[row[0]][0]\n",
    "                timestamp_u_recency_2[num] = np.nan\n",
    "                timestamp_u_recency_3[num] = np.nan\n",
    "                \n",
    "            elif len(timestamp_u[row[0]]) == 2:\n",
    "                timestamp_u_recency_1[num] = row[4] - timestamp_u[row[0]][1]\n",
    "                timestamp_u_recency_2[num] = timestamp_u[row[0]][1] - timestamp_u[row[0]][0]\n",
    "                timestamp_u_recency_3[num] = np.nan\n",
    "            elif len(timestamp_u[row[0]]) == 3:\n",
    "                timestamp_u_recency_1[num] = row[4] - timestamp_u[row[0]][2]\n",
    "                timestamp_u_recency_2[num] = timestamp_u[row[0]][2] - timestamp_u[row[0]][1]\n",
    "                timestamp_u_recency_3[num] = timestamp_u[row[0]][1] - timestamp_u[row[0]][0]\n",
    "                \n",
    "\n",
    "            if len(timestamp_u_incorrect[row[0]]) == 0:\n",
    "                timestamp_u_incorrect_recency[num] = np.nan\n",
    "            else:\n",
    "                timestamp_u_incorrect_recency[num] = row[4] - timestamp_u_incorrect[row[0]][0]\n",
    "                \n",
    "            if part_u_count[row[0]][row[6]]!=0:\n",
    "                part_u_avg[num]=part_u_sum[row[0]][row[6]]/part_u_count[row[0]][row[6]]\n",
    "            else:\n",
    "                part_u_avg[num]=np.nan\n",
    "            \n",
    "            if tags_u_count[row[0]][row[7]]!=0:\n",
    "                tags_u_avg[num]=tags_u_sum[row[0]][row[7]]/tags_u_count[row[0]][row[7]]\n",
    "            else:\n",
    "                tags_u_avg[num]=np.nan\n",
    "                \n",
    "            user_count[num]=answered_correctly_u_count[row[0]]\n",
    "            user_part_count[num]=part_u_count[row[0]][row[6]]\n",
    "            \n",
    "            if timestamp_u_correct[row[0]]!=0:\n",
    "                timestamp_u_correct_recency[num]=row[4] - timestamp_u_correct[row[0]]\n",
    "            else:\n",
    "                timestamp_u_correct_recency[num]=np.nan\n",
    "                \n",
    "            \n",
    "            # ------------------------------------------------------------------\n",
    "            # Community features assignation\n",
    "            \n",
    "            if community_u_count[row[0]][row[9]]!=0:\n",
    "                community_u_avg[num]=community_u_sum[row[0]][row[9]]/community_u_count[row[0]][row[9]]\n",
    "            else:\n",
    "                community_u_avg[num]=np.nan\n",
    "            # ------------------------------------------------------------------\n",
    "            # Bundle features assignation                \n",
    "            if first_bundle_dict[row[0]]!=0:\n",
    "                first_bundle[num]=first_bundle_dict[row[0]]\n",
    "            else:\n",
    "                first_bundle[num]=np.nan\n",
    "            # ------------------------------------------------------------------\n",
    "            # Lectures features assignation\n",
    "            if timestamp_l[row[0]]!=0:\n",
    "                timestamp_l_recency_1[num]=row[4]-timestamp_l[row[0]]\n",
    "            else:\n",
    "                timestamp_l_recency_1[num]=np.nan\n",
    "                \n",
    "            nb_u_lect_watched[num]=nb_l_watched[row[0]]\n",
    "            # ------------------------------------------------------------------\n",
    "            # Client Question assignation\n",
    "            answered_correctly_uq_count[num] = answered_correctly_uq[row[0]][row[1]]\n",
    "            # ------------------------------------------------------------------\n",
    "            # ------------------------------------------------------------------\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            iteration+=1\n",
    "            nb_l_watched[row[0]]+=1\n",
    "            \n",
    "            timestamp_l[row[0]]=row[4]\n",
    "            \n",
    "    user_df = pd.DataFrame({'answered_correctly_u_avg': answered_correctly_u_avg, 'elapsed_time_u_avg': elapsed_time_u_avg, 'explanation_u_avg': explanation_u_avg,  \n",
    "                            'answered_correctly_uq_count': answered_correctly_uq_count, 'timestamp_u_recency_1': timestamp_u_recency_1, 'timestamp_u_recency_2': timestamp_u_recency_2,\n",
    "                            'timestamp_u_recency_3': timestamp_u_recency_3, \n",
    "                             'timestamp_u_incorrect_recency': timestamp_u_incorrect_recency, 'timestamp_l_recency_1': timestamp_l_recency_1, \n",
    "                            'nb_u_lect_watched':nb_u_lect_watched,'part_u_avg':part_u_avg,'tags_u_avg':tags_u_avg,'user_count':user_count,'user_part_count':user_part_count,\n",
    "                        'first_bundle':first_bundle,\n",
    "                           'community_u_avg':community_u_avg,'timestamp_u_correct_recency':timestamp_u_correct_recency})\n",
    "    \n",
    "    df = df.loc[df.content_type_id == False].reset_index(drop = True)\n",
    "    \n",
    "    df = pd.concat([df, user_df], axis = 1)\n",
    "    \n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-01T10:18:56.499378Z",
     "iopub.status.busy": "2021-01-01T10:18:56.494066Z",
     "iopub.status.idle": "2021-01-01T10:18:56.510204Z",
     "shell.execute_reply": "2021-01-01T10:18:56.509465Z"
    },
    "papermill": {
     "duration": 0.043572,
     "end_time": "2021-01-01T10:18:56.510345",
     "exception": false,
     "start_time": "2021-01-01T10:18:56.466773",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def inference(TARGET, FEATURES, model, prior_question_elapsed_time_mean, features_dicts, questions_df,agg, part):\n",
    "    \n",
    "    # Get feature dict\n",
    "    answered_correctly_u_count = features_dicts['answered_correctly_u_count']\n",
    "    answered_correctly_u_sum = features_dicts['answered_correctly_u_sum']\n",
    "    elapsed_time_u_sum = features_dicts['elapsed_time_u_sum']\n",
    "    explanation_u_sum = features_dicts['explanation_u_sum']\n",
    "    answered_correctly_uq = features_dicts['answered_correctly_uq']\n",
    "    timestamp_u = features_dicts['timestamp_u']\n",
    "    timestamp_u_incorrect = features_dicts['timestamp_u_incorrect']\n",
    "    timestamp_u_correct = features_dicts['timestamp_u_correct']\n",
    "    nb_l_watched= features_dicts['nb_l_watched']\n",
    "    timestamp_l = features_dicts['timestamp_l']\n",
    "    part_u_count= features_dicts['part_u_count']\n",
    "    part_u_sum= features_dicts['part_u_sum']\n",
    "    tags_u_count=features_dicts['tags_u_count']\n",
    "    tags_u_sum=features_dicts['tags_u_sum']\n",
    "    first_bundle_dict=features_dicts['first_bundle_dict']\n",
    "    community_u_sum= features_dicts['community_u_sum']\n",
    "    community_u_count= features_dicts['community_u_count']\n",
    "    \n",
    "    # Get api iterator and predictor\n",
    "    env = riiideducation.make_env()\n",
    "    iter_test = env.iter_test()\n",
    "    \n",
    "    \n",
    "    previous_test_df = None\n",
    "    for (test_df, sample_prediction_df) in iter_test:\n",
    "        if previous_test_df is not None:\n",
    "            previous_test_df[TARGET] = eval(test_df[\"prior_group_answers_correct\"].iloc[0])\n",
    "            update_features(previous_test_df,answered_correctly_u_count, answered_correctly_u_sum, elapsed_time_u_sum, explanation_u_sum, timestamp_u, timestamp_u_incorrect, answered_correctly_uq,timestamp_l, nb_l_watched, part_u_count,part_u_sum, tags_u_count,tags_u_sum,first_bundle_dict,community_u_sum,community_u_count, timestamp_u_correct)\n",
    "   \n",
    "        test_df=pd.merge(test_df, questions_df[['question_id', 'part','tags1','bundle_id','community','tags_encoded']], left_on = 'content_id', right_on = 'question_id', how = 'left')\n",
    "        \n",
    "        test_df['prior_question_had_explanation'] = test_df.prior_question_had_explanation.fillna(False).astype('int8')\n",
    "        test_df['prior_question_elapsed_time'].fillna(prior_question_elapsed_time_mean, inplace = True)\n",
    "        \n",
    "        previous_test_df = test_df.copy()\n",
    "        \n",
    "        test_df = add_features_inf(test_df, answered_correctly_u_count, answered_correctly_u_sum, elapsed_time_u_sum, explanation_u_sum, timestamp_u, timestamp_u_incorrect, answered_correctly_uq,timestamp_l, nb_l_watched, part_u_count,part_u_sum, tags_u_count,tags_u_sum,first_bundle_dict,community_u_sum,community_u_count, timestamp_u_correct)\n",
    "   \n",
    "        \n",
    "        test_df = test_df[test_df['content_type_id'] == 0].reset_index(drop = True)\n",
    "        \n",
    "        test_df = pd.merge(test_df, agg, on = 'content_id', how = 'left')\n",
    "        test_df = pd.merge(test_df, part, on = 'part', how = 'left')\n",
    "    \n",
    "        test_df[TARGET] =  model.predict(test_df[FEATURES])\n",
    "        env.predict(test_df[['row_id', TARGET]])\n",
    "        \n",
    "    print('Job Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-01T10:18:56.562934Z",
     "iopub.status.busy": "2021-01-01T10:18:56.562228Z",
     "iopub.status.idle": "2021-01-01T10:18:56.969191Z",
     "shell.execute_reply": "2021-01-01T10:18:56.970175Z"
    },
    "papermill": {
     "duration": 0.441172,
     "end_time": "2021-01-01T10:18:56.970441",
     "exception": false,
     "start_time": "2021-01-01T10:18:56.529269",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job Done\n",
      "CPU times: user 1.04 s, sys: 41 ms, total: 1.08 s\n",
      "Wall time: 411 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "inference(TARGET, FEATURES, model, prior_question_elapsed_time_mean, features_dicts,questions_df, agg, part)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.026367,
     "end_time": "2021-01-01T10:18:57.021919",
     "exception": false,
     "start_time": "2021-01-01T10:18:56.995552",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "papermill": {
   "duration": 2950.13218,
   "end_time": "2021-01-01T10:18:58.598445",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-01-01T09:29:48.466265",
   "version": "2.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
